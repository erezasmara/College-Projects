# Toxic Comments Classification Naive base
Project Structure:
```
├─ Classification_NAIVE_BASE
│  ├─ NAIVE_BAYES.py
│  ├─ test.csv
│  ├─ train.csv
```
Description:
model that’s capable of detecting if comment is a toxic. base on naive base models

Requirement:
- Python 3.8 or above
- pip module
- pandas module
- sklearn module
- termcolor module
- data set train.csv & test.csv


Installation with pip
```
## sudo python3 -m pip install -U pandas
## sudo python3 -m pip install -U scikit-learn
## sudo python3 -m pip install -U termcolor
```
Start:

python3 NAIVE_BAYES.py
### Pictures:

Accuracy

![](https://user-images.githubusercontent.com/33747218/137727248-6aeefd12-c15a-4a24-ad08-823fd69b88bc.png)

![](https://user-images.githubusercontent.com/33747218/137727253-bf56190a-1286-4fe4-9af4-ac4eb82c1ed8.png)

![](https://user-images.githubusercontent.com/33747218/137727256-0e514ce1-9c3e-417f-a280-ce89b0d0428f.png)

detect a toxic comment
![](https://user-images.githubusercontent.com/33747218/137727258-c82727f4-b16d-4dc8-852a-d3b6cce4f772.png)

